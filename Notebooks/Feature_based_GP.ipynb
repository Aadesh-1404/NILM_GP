{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from gpytorch.kernels import (\n",
    "    RBFKernel,\n",
    "    ScaleKernel,\n",
    "    PeriodicKernel,\n",
    "    MaternKernel,\n",
    "    CosineKernel,\n",
    "    LinearKernel,\n",
    ")\n",
    "from skgpytorch.models import SVGPRegressor, SGPRegressor\n",
    "from scipy.stats import kurtosis, skew\n",
    "import jax.numpy as jnp\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow_probability.substrates.jax as tfp\n",
    "\n",
    "dist = tfp.distributions\n",
    "import pandas as pd\n",
    "import jax.numpy as jnp\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from utilities import plot, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latexify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from probml_utils import latexify, savefig, is_latexify_enabled\n",
    "except ModuleNotFoundError:\n",
    "    %pip install git+https://github.com/probml/probml-utils.git\n",
    "    from probml_utils import latexify, savefig, is_latexify_enabled\n",
    "os.environ[\"LATEXIFY\"] = \"1\"\n",
    "os.environ[\"FIG_DIR\"] = \"./Figures/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jax.numpy as jnp\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def dataset_load(appliances, train, test=None, bias=False):\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_train_timestamp = []\n",
    "    x_train_mean = []\n",
    "    x_train_std = []\n",
    "    x_train_max_min = []\n",
    "    x_train_main = []\n",
    "    x_train_max = []\n",
    "    x_train_min = []\n",
    "    x_train_kurtosis = []\n",
    "    x_train_skew = []\n",
    "    n = 99\n",
    "    m = 9\n",
    "    units_to_pad = n // 2\n",
    "    units_to_pad1 = m // 2\n",
    "    scaler_x = StandardScaler()\n",
    "    scaler_y = StandardScaler()\n",
    "    scaler_time = StandardScaler()\n",
    "    scaler_mean = StandardScaler()\n",
    "    scaler_std = StandardScaler()\n",
    "    scaler_max_min = StandardScaler()\n",
    "    scaler_main = StandardScaler()\n",
    "    scaler_max = StandardScaler()\n",
    "    scaler_min = StandardScaler()\n",
    "    scaler_kurtosis = StandardScaler()\n",
    "    scaler_skew = StandardScaler()\n",
    "\n",
    "    ## train\n",
    "    for key, values in train.items():\n",
    "        for app in range(len(appliances)):\n",
    "            df = pd.read_csv(\n",
    "                f\"Data/Building{key}_NILM_data_basic.csv\",\n",
    "                usecols=[\"Timestamp\", \"main\", appliances[app]],\n",
    "            )\n",
    "            df[\"date\"] = pd.to_datetime(df[\"Timestamp\"]).dt.date\n",
    "            startDate = datetime.strptime(values[\"start_time\"], \"%Y-%m-%d\").date()\n",
    "            endDate = datetime.strptime(values[\"end_time\"], \"%Y-%m-%d\").date()\n",
    "\n",
    "            if startDate > endDate:\n",
    "                raise \"Start Date must be smaller than Enddate.\"\n",
    "\n",
    "            df = df[(df[\"date\"] >= startDate) & (df[\"date\"] <= endDate)]\n",
    "            df.dropna(inplace=True)\n",
    "            if app == 0:\n",
    "                x = df[appliances[app]].values\n",
    "            else:\n",
    "                x += df[appliances[app]].values\n",
    "            if appliances[app] == \"Refrigerator\":\n",
    "                y = df[appliances[app]].values\n",
    "        x_train_main.extend(x)\n",
    "        timestamp_train = (\n",
    "            pd.to_datetime(df[\"Timestamp\"]).astype(int) / 10**18\n",
    "        ).values\n",
    "        x2 = x\n",
    "        x = jnp.pad(x, (units_to_pad, units_to_pad), \"constant\", constant_values=(0, 0))\n",
    "        x = jnp.array([x[i : i + n] for i in range(len(x) - n + 1)])\n",
    "        x_train_mean.extend(jnp.mean(x, axis=1))\n",
    "        x_train_std.extend(jnp.std(x, axis=1))\n",
    "        x1 = jnp.pad(\n",
    "            x2, (units_to_pad1, units_to_pad1), \"constant\", constant_values=(0, 0)\n",
    "        )\n",
    "        x1 = jnp.array([x1[i : i + m] for i in range(len(x1) - m + 1)])\n",
    "        x_train_max_min.extend(jnp.max(x, axis=1) - jnp.min(x, axis=1))\n",
    "        x_train_max.extend(jnp.max(x1, axis=1))\n",
    "        x_train_min.extend(jnp.min(x1, axis=1))\n",
    "        x_train_kurtosis.extend(kurtosis(x, axis=1))\n",
    "        x_train_skew.extend(skew(x, axis=1))\n",
    "        x_train.extend(x)\n",
    "        y_train.extend(y)\n",
    "        x_train_timestamp.extend(torch.tensor(timestamp_train))\n",
    "\n",
    "    x_train = jnp.array(x_train)\n",
    "    y_train = jnp.array(y_train).reshape(-1, 1)\n",
    "    x_train_timestamp = torch.tensor(x_train_timestamp).reshape(-1, 1)\n",
    "    x_train_main = jnp.array(x_train_main).reshape(-1, 1)\n",
    "    x_train_mean = jnp.array(x_train_mean).reshape(-1, 1)\n",
    "    x_train_std = jnp.array(x_train_std).reshape(-1, 1)\n",
    "    x_train_max_min = jnp.array(x_train_max_min).reshape(-1, 1)\n",
    "    x_train_max = jnp.array(x_train_max).reshape(-1, 1)\n",
    "    x_train_skew = jnp.array(x_train_skew).reshape(-1, 1)\n",
    "    x_train_min = jnp.array(x_train_min).reshape(-1, 1)\n",
    "    x_train_kurtosis = jnp.array(x_train_kurtosis).reshape(-1, 1)\n",
    "\n",
    "    x_train = scaler_x.fit_transform(x_train)\n",
    "    y_train = scaler_y.fit_transform(y_train)\n",
    "    x_train_timestamp = scaler_time.fit_transform(x_train_timestamp)\n",
    "    x_train_main = scaler_main.fit_transform(x_train_main)\n",
    "    x_train_mean = scaler_mean.fit_transform(x_train_mean)\n",
    "    x_train_std = scaler_std.fit_transform(x_train_std)\n",
    "    x_train_max_min = scaler_max_min.fit_transform(x_train_max_min)\n",
    "    x_train_max = scaler_max.fit_transform(x_train_max)\n",
    "    x_train_min = scaler_min.fit_transform(x_train_min)\n",
    "    x_train_kurtosis = scaler_kurtosis.fit_transform(x_train_kurtosis)\n",
    "    x_train_skew = scaler_skew.fit_transform(x_train_skew)\n",
    "\n",
    "    # test\n",
    "    x_test = []\n",
    "    y_test = []\n",
    "    x_test_timestamp = []\n",
    "    x_test_mean = []\n",
    "    x_test_std = []\n",
    "    x_test_max_min = []\n",
    "    x_test_timestamp_true = []\n",
    "    x_test_main = []\n",
    "    x_test_max = []\n",
    "    x_test_min = []\n",
    "    x_test_kurtosis = []\n",
    "    x_test_skew = []\n",
    "\n",
    "    for key, values in test.items():\n",
    "        for app in range(len(appliances)):\n",
    "            df = pd.read_csv(\n",
    "                f\"Data/Building{key}_NILM_data_basic.csv\",\n",
    "                usecols=[\"Timestamp\", \"main\", appliances[app]],\n",
    "            )\n",
    "            df[\"date\"] = pd.to_datetime(df[\"Timestamp\"]).dt.date\n",
    "            startDate = datetime.strptime(values[\"start_time\"], \"%Y-%m-%d\").date()\n",
    "            endDate = datetime.strptime(values[\"end_time\"], \"%Y-%m-%d\").date()\n",
    "\n",
    "            if startDate > endDate:\n",
    "                raise \"Start Date must be smaller than Enddate.\"\n",
    "\n",
    "            df = df[(df[\"date\"] >= startDate) & (df[\"date\"] <= endDate)]\n",
    "            df.dropna(inplace=True)\n",
    "\n",
    "            if app == 0:\n",
    "                x = df[appliances[app]].values\n",
    "            else:\n",
    "                x += df[appliances[app]].values\n",
    "            if appliances[app] == \"Refrigerator\":\n",
    "                y = df[appliances[app]].values\n",
    "\n",
    "        if bias == True:\n",
    "            x = x + 100 * np.ones(x.shape[0])\n",
    "\n",
    "        x_test_main.extend(x)\n",
    "        timestamp_true = df[\"Timestamp\"].values\n",
    "        timestamp = (pd.to_datetime(df[\"Timestamp\"]).astype(int) / 10**18).values\n",
    "        x2 = x\n",
    "        x = jnp.pad(x, (units_to_pad, units_to_pad), \"constant\", constant_values=(0, 0))\n",
    "        x = jnp.array([x[i : i + n] for i in range(len(x) - n + 1)])\n",
    "\n",
    "        x_test_mean.extend(jnp.mean(x, axis=1))\n",
    "        x_test_std.extend(jnp.std(x, axis=1))\n",
    "        x1 = jnp.pad(\n",
    "            x2, (units_to_pad1, units_to_pad1), \"constant\", constant_values=(0, 0)\n",
    "        )\n",
    "        x1 = jnp.array([x1[i : i + m] for i in range(len(x1) - m + 1)])\n",
    "        x_test_max_min.extend(jnp.max(x, axis=1) - jnp.min(x, axis=1))\n",
    "        x_test_max.extend(jnp.max(x1, axis=1))\n",
    "        x_test_min.extend(jnp.min(x1, axis=1))\n",
    "        x_test.extend(x)\n",
    "        x_test_kurtosis.extend(kurtosis(x, axis=1))\n",
    "        x_test_skew.extend(skew(x, axis=1))\n",
    "        y_test.extend(y)\n",
    "        x_test_timestamp_true.extend(timestamp_true)\n",
    "        x_test_timestamp.extend(timestamp)\n",
    "\n",
    "    x_test = jnp.array(x_test)\n",
    "    y_test = jnp.array(y_test).reshape(-1, 1)\n",
    "    x_test_timestamp = torch.tensor(x_test_timestamp).reshape(-1, 1)\n",
    "    x_test_main = jnp.array(x_test_main).reshape(-1, 1)\n",
    "    x_test_mean = jnp.array(x_test_mean).reshape(-1, 1)\n",
    "    x_test_std = jnp.array(x_test_std).reshape(-1, 1)\n",
    "    x_test_max_min = jnp.array(x_test_max_min).reshape(-1, 1)\n",
    "    x_test_max = jnp.array(x_test_max).reshape(-1, 1)\n",
    "    x_test_min = jnp.array(x_test_min).reshape(-1, 1)\n",
    "    x_test_kurtosis = jnp.array(x_test_kurtosis).reshape(-1, 1)\n",
    "    x_test_skew = jnp.array(x_test_skew).reshape(-1, 1)\n",
    "\n",
    "    x_test = scaler_x.transform(x_test)\n",
    "    x_test_timestamp = scaler_time.transform(x_test_timestamp)\n",
    "    x_test_mean = scaler_mean.transform(x_test_mean)\n",
    "    x_test_std = scaler_std.transform(x_test_std)\n",
    "    x_test_max_min = scaler_max_min.transform(x_test_max_min)\n",
    "    x_test_main = scaler_main.transform(x_test_main)\n",
    "    x_test_max = scaler_max.transform(x_test_max)\n",
    "    x_test_min = scaler_min.transform(x_test_min)\n",
    "    x_test_kurtosis = scaler_kurtosis.transform(x_test_kurtosis)\n",
    "    x_test_skew = scaler_skew.transform(x_test_skew)\n",
    "\n",
    "    x_train = jnp.array(x_train[:, 1:]).reshape(x_train.shape[0], n - 1)\n",
    "    y_train = jnp.array(y_train)\n",
    "    x_train_timestamp = torch.tensor(x_train_timestamp).reshape(\n",
    "        x_train_timestamp.shape[0], 1\n",
    "    )\n",
    "    x_test = jnp.array(x_test[:, 1:]).reshape(x_test.shape[0], n - 1)\n",
    "    y_test = jnp.array(y_test)\n",
    "    x_test_timestamp = (\n",
    "        torch.tensor(x_test_timestamp)\n",
    "        .reshape(x_test_timestamp.shape[0], 1)\n",
    "        .to(torch.float64)\n",
    "    )\n",
    "\n",
    "    num_features_selected = 6\n",
    "    x_train_features = jnp.concatenate(\n",
    "        (\n",
    "            x_train_main,\n",
    "            x_train_mean,\n",
    "            x_train_max_min,\n",
    "            x_train_max,\n",
    "            x_train_min,\n",
    "            x_train_kurtosis,\n",
    "        ),\n",
    "        axis=1,\n",
    "    ).reshape(x_train.shape[0], num_features_selected)\n",
    "    x_test_features = jnp.concatenate(\n",
    "        (\n",
    "            x_test_main,\n",
    "            x_test_mean,\n",
    "            x_test_max_min,\n",
    "            x_test_max,\n",
    "            x_test_min,\n",
    "            x_test_kurtosis,\n",
    "        ),\n",
    "        axis=1,\n",
    "    ).reshape(x_test.shape[0], num_features_selected)\n",
    "\n",
    "    scalers = np.array(\n",
    "        [\n",
    "            scaler_x,\n",
    "            scaler_y,\n",
    "            scaler_time,\n",
    "            scaler_main,\n",
    "            scaler_mean,\n",
    "            scaler_std,\n",
    "            scaler_max_min,\n",
    "            scaler_max,\n",
    "            scaler_min,\n",
    "            scaler_kurtosis,\n",
    "            scaler_skew,\n",
    "        ]\n",
    "    )\n",
    "    return (\n",
    "        x_train,\n",
    "        y_train,\n",
    "        x_test,\n",
    "        y_test,\n",
    "        x_train_features,\n",
    "        x_test_features,\n",
    "        x_train_timestamp,\n",
    "        x_test_timestamp,\n",
    "        scalers,\n",
    "        x_test_main,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = {\n",
    "    1: {\"start_time\": \"2011-04-28\", \"end_time\": \"2011-05-15\"},\n",
    "    3: {\"start_time\": \"2011-04-19\", \"end_time\": \"2011-05-22\"},\n",
    "}\n",
    "\n",
    "test = {\n",
    "    2: {\"start_time\": \"2011-04-21\", \"end_time\": \"2011-05-21\"},\n",
    "}\n",
    "appliances = [\"Microwave\", \"Refrigerator\", \"Dish Washer\"]  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = False\n",
    "(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    x_test,\n",
    "    y_test,\n",
    "    x_train_features,\n",
    "    x_test_features,\n",
    "    x_train_timstamp,\n",
    "    x_test_timestamp,\n",
    "    scalers,\n",
    "    x_test_main,\n",
    ") = dataset_load(appliances, train, test, bias=bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_diff = x_train_features[:, 0]\n",
    "diff1 = np.array(x_train_diff)\n",
    "for i in range(1, len(x_train_diff)):\n",
    "\t\tvalue = x_train_diff[i] - x_train_diff[i - 1]\n",
    "\t\tdiff1[i] = value\n",
    "\n",
    "x_test_diff = x_test_features[:, 0]\n",
    "diff2 = np.array(x_test_diff)\n",
    "for i in range(1, len(x_test_diff)):\n",
    "\t\tvalue = x_test_diff[i] - x_test_diff[i - 1]\n",
    "\t\tdiff2[i] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_features = jnp.concatenate(\n",
    "    (x_train_features, jnp.array(np.array(x_train_diff.reshape(-1, 1)))), axis=1\n",
    ")\n",
    "x_test_features = jnp.concatenate(\n",
    "    (x_test_features, jnp.array(np.array(x_test_diff.reshape(-1, 1)))), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = x_train_features.shape[1]\n",
    "x = torch.tensor(np.array(x_train_features)).to(torch.float64)\n",
    "y = (\n",
    "    torch.tensor(np.array(y_train))\n",
    "    .reshape(\n",
    "        -1,\n",
    "    )\n",
    "    .to(torch.float64)\n",
    ")\n",
    "xt = torch.tensor(np.array(x_test_features)).to(torch.float64)\n",
    "yt = (\n",
    "    torch.tensor(np.array(y_test))\n",
    "    .reshape(\n",
    "        -1,\n",
    "    )\n",
    "    .to(torch.float64)\n",
    ")\n",
    "x.shape, y.shape, xt.shape, yt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GP_model(train, test, linear, ard, model_name):\n",
    "    kernel1 = ScaleKernel(MaternKernel(nu=2.5, ard_num_dims=ard))\n",
    "    kernel = kernel1\n",
    "    if linear:\n",
    "        kernel2 = ScaleKernel(LinearKernel(active_dims=(3)))\n",
    "        kernel = kernel1 + kernel2\n",
    "    inducing_points = x[np.arange(0, x.shape[0], 95)]\n",
    "\n",
    "    model = SGPRegressor(x.to(\"cuda\"), y.to(\"cuda\"), kernel, inducing_points).to(\"cuda\")\n",
    "    if train:\n",
    "        loss = model.fit(lr=1e-2, n_epochs=1500, verbose=1, random_state=0)\n",
    "\n",
    "        plt.plot(np.asarray(loss[0]))\n",
    "\n",
    "        model_name = model_name\n",
    "        torch.save(model.state_dict(), os.path.join(\"./models\", model_name))\n",
    "    if test:\n",
    "        model_name = model_name\n",
    "        model.load_state_dict(torch.load(os.path.join(\"./models\", model_name)))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = True\n",
    "if linear:\n",
    "    model_name = \"feature_final_linear.pt\"\n",
    "else:\n",
    "    model_name = \"feature_final.pt\"\n",
    "\n",
    "model = GP_model(train=False, test=True, linear=linear, ard=n, model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 4(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if linear:\n",
    "    if bias == False:\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        latexify(width_scale_factor=3, fig_height=1.75)\n",
    "        ax.bar(\n",
    "            range(7),\n",
    "            model.mll.model.base_covar_module.kernels[0]\n",
    "            .base_kernel.lengthscale.cpu()\n",
    "            .detach()\n",
    "            .reshape(-1, 1)[:7],\n",
    "        )\n",
    "        x_ticks_labels = [\n",
    "            \"Main\",\n",
    "            \"Mean\",\n",
    "            \"Range\",\n",
    "            \"Max\",\n",
    "            \"Min\",\n",
    "            \"Kurtosis\",\n",
    "            \"Difference\",\n",
    "        ]\n",
    "        sns.despine()\n",
    "        # ax.set_xlabel(\"Number of features\")\n",
    "        ax.set_ylabel(\"LengthScale of features\")\n",
    "        # ax.set_xticklabels(x_ticks_labels, rotation='vertical')\n",
    "        plt.xticks(range(len(x_ticks_labels)), x_ticks_labels, rotation=\"vertical\")\n",
    "        savefig(\"ARD_features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dist = model.predict((xt).to(\"cuda\"))\n",
    "y_mean = pred_dist.loc\n",
    "y_mean = scalers[1].inverse_transform(y_mean.reshape(-1, 1).cpu()).squeeze()\n",
    "\n",
    "print(y_test.shape, y_mean.shape)\n",
    "y_mean = np.clip(y_mean, 0, y_mean.max(), out=y_mean)\n",
    "var_pred = pred_dist.variance\n",
    "var_pred = (\n",
    "    scalers[1].inverse_transform(var_pred.reshape(-1, 1).detach().cpu()).squeeze()\n",
    ")\n",
    "std_pred = pred_dist.stddev\n",
    "std_pred = torch.tensor(\n",
    "    scalers[1].inverse_transform(std_pred.reshape(-1, 1).detach().cpu()).squeeze()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = errors.mae(torch.tensor(y_mean), yt)\n",
    "msll = errors.msll(var_pred, y_mean, yt)\n",
    "qce = errors.qce(std_pred, y_mean, yt)\n",
    "print(\"mae, msll, qce - \", mae, msll, qce)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 4 (b) and Figures 5 (c), (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = [4800]\n",
    "idx = [200]\n",
    "\n",
    "if bias:\n",
    "    start = [4170]\n",
    "    idx = [300]\n",
    "\n",
    "x1 = x_test_features[:, 0].reshape(-1, 1)\n",
    "x = scalers[3].inverse_transform(x1)\n",
    "i = 0\n",
    "for i in range(len(start)):\n",
    "    if bias:\n",
    "        if linear == False:\n",
    "            plot.prediction_plots(\n",
    "                x, yt, y_mean, start[i], idx[i], var_pred, \"features_bias\", 0\n",
    "            )\n",
    "        else:\n",
    "            plot.prediction_plots(\n",
    "                x, yt, y_mean, start[i], idx[i], var_pred, \"features_bias_linear\", 1\n",
    "            )\n",
    "    else:\n",
    "        plot.prediction_plots(\n",
    "            x, yt, y_mean, start[i], idx[i], var_pred, \"features_1\", 1\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "latexify(width_scale_factor=2.5, fig_height=1.75)\n",
    "sigma_pred = jnp.sqrt(var_pred)\n",
    "df, df1 = plot.calibration_regression(\n",
    "    y_mean.squeeze(), sigma_pred.squeeze(), y_test.squeeze(), \"test\", \"r\", ax\n",
    ")\n",
    "ax.legend()\n",
    "if bias:\n",
    "    if linear:\n",
    "        savefig(\"Features_linear_bias_calibration\")\n",
    "    else:\n",
    "        savefig(\"Features_bias_calibration\")\n",
    "elif linear:\n",
    "    savefig(\"Features_linear_calibration\")\n",
    "else:\n",
    "    savefig(\"Features_calibration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal = errors.find_p_hat(np.array(yt), y_mean, sigma_pred)\n",
    "p = cal.index\n",
    "mae_cal = errors.ace(p.values, cal.values)\n",
    "print(\"calibration error: \", mae_cal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 4 (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_lin_max = 3000\n",
    "x_lin = np.linspace(0, x_lin_max, 15656)\n",
    "x_time = np.linspace(\n",
    "    scalers[2].inverse_transform(x_test_timestamp.reshape(-1, 1)).min(),\n",
    "    scalers[2].inverse_transform(x_test_timestamp.reshape(-1, 1)).max(),\n",
    "    15656,\n",
    ")\n",
    "x_range = np.linspace(\n",
    "    scalers[6].inverse_transform(x_test_features[2].reshape(-1, 1)).min(),\n",
    "    scalers[6].inverse_transform(x_test_features[2].reshape(-1, 1)).max(),\n",
    "    15656,\n",
    ")\n",
    "x_max = np.linspace(\n",
    "    scalers[7].inverse_transform(x_test_features[3].reshape(-1, 1)).min(),\n",
    "    scalers[7].inverse_transform(x_test_features[3].reshape(-1, 1)).max(),\n",
    "    15656,\n",
    ")\n",
    "x_min = np.linspace(\n",
    "    scalers[8].inverse_transform(x_test_features[4].reshape(-1, 1)).min(),\n",
    "    scalers[8].inverse_transform(x_test_features[4].reshape(-1, 1)).max(),\n",
    "    15656,\n",
    ")\n",
    "x_diff = np.linspace(\n",
    "    scalers[3].inverse_transform(x_test_features[5].reshape(-1, 1)).min(),\n",
    "    scalers[3].inverse_transform(x_test_features[5].reshape(-1, 1)).max(),\n",
    "    15656,\n",
    ")\n",
    "x_mean = np.linspace(\n",
    "    scalers[4].inverse_transform(x_test_features[1].reshape(-1, 1)).min(),\n",
    "    scalers[4].inverse_transform(x_test_features[1].reshape(-1, 1)).max(),\n",
    "    15656,\n",
    ")\n",
    "x_kur = np.linspace(\n",
    "    scalers[9].inverse_transform(x_test_features[6].reshape(-1, 1)).min(),\n",
    "    scalers[9].inverse_transform(x_test_features[6].reshape(-1, 1)).max(),\n",
    "    15656,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_lin_scale = torch.tensor(scalers[3].transform(x_lin.reshape(-1, 1))).to(torch.float32)\n",
    "x_lin_dif = x_lin_scale\n",
    "diff_scale = np.array(x_lin_dif)\n",
    "for i in range(1, len(x_lin_dif)):\n",
    "    value = x_lin_dif[i] - x_lin_dif[i - 1]\n",
    "    diff_scale[i] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_time_scale = torch.tensor(scalers[2].transform(x_time.reshape(-1, 1))).to(\n",
    "    torch.float32\n",
    ")\n",
    "x_range_scale = torch.tensor(diff_scale.reshape(-1, 1)).to(torch.float32)\n",
    "x_max_scale = torch.tensor(scalers[7].transform(x_max.reshape(-1, 1))).to(torch.float32)\n",
    "x_min_scale = torch.tensor(scalers[8].transform(x_min.reshape(-1, 1))).to(torch.float32)\n",
    "x_dif_scale = torch.tensor(scalers[3].transform(x_diff.reshape(-1, 1))).to(\n",
    "    torch.float32\n",
    ")\n",
    "x_mean_scale = torch.tensor(scalers[4].transform(x_mean.reshape(-1, 1))).to(\n",
    "    torch.float32\n",
    ")\n",
    "x_kur_scale = torch.tensor(scalers[9].transform(x_kur.reshape(-1, 1))).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = torch.cat(\n",
    "    (\n",
    "        x_lin_scale,\n",
    "        x_mean_scale,\n",
    "        x_range_scale,\n",
    "        x_max_scale,\n",
    "        x_min_scale,\n",
    "        x_kur_scale,\n",
    "        x_dif_scale,\n",
    "    ),\n",
    "    dim=1,\n",
    ").to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new.shape, x_new.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dist = model.predict(x_new.to(\"cuda\"))\n",
    "y_mean = pred_dist.loc\n",
    "y_mean = scalers[1].inverse_transform(y_mean.cpu().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "latexify(width_scale_factor=2, fig_height=1.5)\n",
    "start = 500\n",
    "idx = 4000\n",
    "plt.plot(x_lin, y_mean, \"k\", label=\" Predicted Mean\", alpha=0.7)\n",
    "plt.scatter(\n",
    "    scalers[3].inverse_transform(x_train_features[:, 0].reshape(-1, 1)),\n",
    "    scalers[1].inverse_transform(y_train.reshape(-1, 1)),\n",
    "    s=6,\n",
    "    label=\"Appliance Power\",\n",
    ")\n",
    "plt.xlim(00, 1500)\n",
    "sns.despine()\n",
    "# plt.title(\"Train Mains Vs Train Applaince along with Predicted Means\")\n",
    "plt.legend(frameon=False, bbox_to_anchor=(0.4, 0.6))\n",
    "plt.xlabel(\"Train Mains\")\n",
    "plt.ylabel(\"Train Appliance Power\")\n",
    "# plt.show()\n",
    "savefig(\"features_vs_app_mean\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('nlim')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4a19952a8cb0d513e360355f3718fc7b5b0ccef7313ddd97e7b7ab66b1ecfbb8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
